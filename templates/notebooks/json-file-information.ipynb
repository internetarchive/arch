{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAyuRQ2PJIdc"
   },
   "source": [
    "# JSON Information Dataset Exploration\n",
    "\n",
    "We're going to take a look at a few examples of how we can explore the JSON Information dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfhJiesWVpAf",
    "outputId": "67472059-8869-4a7c-c8bb-01ab9c96d323"
   },
   "outputs": [],
   "source": [
    "dataset = \"ARCHDATASETURL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z14F2cIWJVW0"
   },
   "source": [
    "## pandas\n",
    "\n",
    "Next, we'll setup our environment so we can load our JSON Information dataset into [pandas](https://pandas.pydata.org) DataFrames. If you're unfamiliar with DataFrames, but you've worked with spreadsheets before, you should feel comfortable pretty quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Chh6tt3HHF1s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sH81XCf3I3xY"
   },
   "source": [
    "## Data Table Display\n",
    "\n",
    "Colab includes an extension that renders pandas DataFrames into interactive displays that can be filtered, sorted, and explored dynamically. This can be very useful for taking a look at what each DataFrame provides, and doing some intital filtering!\n",
    "\n",
    "Data table display for pandas DataFrames can be enabled by running:\n",
    "```python\n",
    "%load_ext google.colab.data_table\n",
    "```\n",
    "and disabled by running\n",
    "```python\n",
    "%unload_ext google.colab.data_table\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qyCnbvBI7n6"
   },
   "outputs": [],
   "source": [
    "%load_ext google.colab.data_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6prR7j1zI_D5"
   },
   "source": [
    "## Loading our ARCH Dataset as a DataFrame\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Next, we'll create pandas DataFrame from our dataset, and show a preview of it using the Data Table Display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "id": "YL0LQaUNHRKx",
    "outputId": "b6cbb5fb-c318-4d3c-aec9-03393f9bc0a6"
   },
   "outputs": [],
   "source": [
    "json = pd.read_csv(dataset, compression=\"gzip\")\n",
    "json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HPwOCNAvqMe"
   },
   "source": [
    "# Data Analysis\n",
    "\n",
    "Now that we have all of our datasets loaded up, we can begin to work with them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6Pkg0prv3BE"
   },
   "source": [
    "## Counting total files, and unique files\n",
    "\n",
    "Let's take a quick look at how to count items in DataFrames, and use total and unique files as an example to work with.\n",
    "\n",
    "It's definitely work checking out the [pandas documentation](https://pandas.pydata.org/docs/index.html). There are a lot of good examples available, along with a robust [API reference](https://pandas.pydata.org/docs/reference/index.html#api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFX4Gl3wv7bi"
   },
   "source": [
    "\n",
    "### How many JSON files are in this collection?\n",
    "\n",
    "We can take our `json` variable and try a couple of functions to get the same answer.\n",
    "\n",
    "1.   `len(json.index)`\n",
    "  * Get the length of the DataFrame's index.\n",
    "2.   `json.shape[0]`\n",
    "  * Get the shape or dimensionality of the DataFrame, and take the first item in the tuple.\n",
    "3.  `json.count()`\n",
    "  * Count the number of rows for each column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTv8Oet3jiTH",
    "outputId": "963cd7b8-67a3-4be5-fb9f-2923df033e01"
   },
   "outputs": [],
   "source": [
    "len(json.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rYEERnTjifk",
    "outputId": "a13e709c-0e94-4f3e-919f-0a2919be8bb8"
   },
   "outputs": [],
   "source": [
    "json.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bn-1v127aKIG",
    "outputId": "06bb07bb-b1fc-42f3-86f1-1b5157cd9764"
   },
   "outputs": [],
   "source": [
    "json.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38veKiPhwKo4"
   },
   "source": [
    "### How many unique JSON files are in the collection?\n",
    "\n",
    " We can see if a JSON file is unique or not by computing an [MD5 hash](https://en.wikipedia.org/wiki/MD5#MD5_hashes) of it, and comparing them. The exact same JSON file might have a filename of `example.json` or `foo.json`. If the hash is computed for each, we can see that even with different file names, they are actually the same JSON file. So, since we have both a `MD5` and `SHA1` hash column available in our DataFrame, we can just find the unique values, and count them!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WesM3kQowM5B",
    "outputId": "938d1fbb-e508-4232-e431-5bdb228745eb"
   },
   "outputs": [],
   "source": [
    "len(json.md5.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIXkI0-1wWQf"
   },
   "source": [
    "### What are the top 10 most occurring JSON files in the collection?\n",
    "\n",
    "Here we can take advantage of [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) to provide us with a list of MD5 hashes and their respective counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Ts03OFyjPIM",
    "outputId": "48e85917-2373-4d93-8979-461c8b44116b"
   },
   "outputs": [],
   "source": [
    "json[\"md5\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top value as a variable using [`mode()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_occurring = json[\"md5\"].mode()[0]\n",
    "most_occurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FG7pGZUEwlaI"
   },
   "source": [
    "### What's the information around all the most occurring file?\n",
    "\n",
    "Let's find those json files in the DataFrame. We can here see some of the filenames used, MIME types, and its URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "msmmm65lkSIK",
    "outputId": "42054a41-4116-4b93-f2d3-9497ac88998d"
   },
   "outputs": [],
   "source": [
    "json.loc[json[\"md5\"] == most_occurring]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbLLZW2awzCv"
   },
   "source": [
    "### What are the top 10 most occurring filenames in the collection?\n",
    "\n",
    "Note that this is of course different than the MD5 results up above. Here we are focusing _just_ on filename. So `media.json` for example, might actually be referring to different JSON files who happen to have the same name.\n",
    "\n",
    "Here we can use `value_counts()` again, but this time we'll create a variable for the top filenames so we can use it later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQaw54ACkwdZ",
    "outputId": "5bf5d378-5c1c-4322-b600-effecc91f9d0"
   },
   "outputs": [],
   "source": [
    "top_filenames = json[\"filename\"].value_counts().head(10)\n",
    "top_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7F3re20BQRI"
   },
   "source": [
    "### Let's create our first graph!\n",
    "\n",
    "We'll first plot the data with the pandas [plot](https://pandas.pydata.org/docs/reference/api/pandas.Series.plot.html) functionality, and then with [Altair](https://altair-viz.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "sRvlstfsBWEZ",
    "outputId": "e53fe864-a19c-4ed3-c81d-5a73f0837ef1"
   },
   "outputs": [],
   "source": [
    "top_filenames_chart = top_filenames.plot.bar(figsize=(25, 10))\n",
    "\n",
    "top_filenames_chart.set_title(\"Top Filenames\", fontsize=22)\n",
    "top_filenames_chart.set_xlabel(\"Filename\", fontsize=20)\n",
    "top_filenames_chart.set_ylabel(\"Count\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQgeOObvgLvK"
   },
   "source": [
    "Now let's setup [Altair](https://altair-viz.github.io/), and plot the data. Altair is useful for creating vizualizations since they can be easily exported as a PNG or SVG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7Z4J6qjWaVM"
   },
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 828
    },
    "id": "s0xwvILYWkgg",
    "outputId": "47d95b19-d011-4934-a992-178367ce0adc"
   },
   "outputs": [],
   "source": [
    "top_filenames_altair = (\n",
    "    json[\"filename\"]\n",
    "    .value_counts()\n",
    "    .head(10)\n",
    "    .rename_axis(\"Filename\")\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "filenames_bar = (\n",
    "    alt.Chart(top_filenames_altair)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"Filename:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
    ")\n",
    "\n",
    "filenames_rule = (\n",
    "    alt.Chart(top_filenames_altair).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
    ")\n",
    "\n",
    "\n",
    "filenames_text = filenames_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
    "    text=\"Count:Q\"\n",
    ")\n",
    "\n",
    "(filenames_bar + filenames_rule + filenames_text).properties(\n",
    "    width=1400, height=700, title=\"Top Filenames\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BneaN9cgGoly"
   },
   "source": [
    "### How about a file format distribution?\n",
    "\n",
    "What _kind_ of JSON files are present? We can discover this by checking their \"media type\", or [MIME type](https://en.wikipedia.org/wiki/Media_type). \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 823
    },
    "id": "RDd-J8D-GwDk",
    "outputId": "b9752e90-8c8e-4199-ce52-ab0019403f75"
   },
   "outputs": [],
   "source": [
    "json_mime_types = (\n",
    "    json[\"mime_type_tika\"]\n",
    "    .value_counts()\n",
    "    .head(5)\n",
    "    .rename_axis(\"MIME Type\")\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "json_mimes_bar = (\n",
    "    alt.Chart(json_mime_types)\n",
    "    .mark_bar()\n",
    "    .encode(x=alt.X(\"MIME Type:O\", sort=\"-y\"), y=alt.Y(\"Count:Q\"))\n",
    ")\n",
    "\n",
    "json_mime_rule = (\n",
    "    alt.Chart(json_mime_types).mark_rule(color=\"red\").encode(y=\"mean(Count):Q\")\n",
    ")\n",
    "\n",
    "json_mime_text = json_mimes_bar.mark_text(align=\"center\", baseline=\"bottom\").encode(\n",
    "    text=\"Count:Q\"\n",
    ")\n",
    "\n",
    "(json_mimes_bar + json_mime_rule + json_mime_text).properties(\n",
    "    width=1400, height=700, title=\"JSON File Format Distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUJR-jjqNxCL"
   },
   "source": [
    "### How do I get the actual JSON files?\n",
    "\n",
    "...or, how do I get to the actual binary files described by each file format information derivative?\n",
    "\n",
    "There are a few options!\n",
    "\n",
    "1. `wget` or `curl` from the live URL, or a replay URL\n",
    "  * Live web URL\n",
    "    * `wget` or `curl` the value of the `url` column\n",
    "  * Replay web URL\n",
    "    * `wget` or `curl` the value of the `crawl_date` and `url` column using the following pattern:\n",
    "      * `https://web.archive.org/web/` + `crawl_date` + `/` + `url`\n",
    "        * https://web.archive.org/web/20120119124734/http://www.archive.org/images/glogo.png\n",
    "      * `http://wayback.archive-it.org/14462/` + `crawl_date` + `/` + `url`\n",
    "        * https://wayback.archive-it.org/14462/20210524212740/https://ruebot.net/visualization/elxn42/featured_hu33a17dfb90e2c5ed77f783db14a6e53a_5126291_550x0_resize_q90_box_2.png\n",
    "2. Use a scripting language, such as Python\n",
    "  * Make use of the `url` and `filename` columns (and `crawl_date` if you want to use the replay URL)\n",
    "  * `import requests`\n",
    "  * `requests.get(url, allow_redirects=True)`\n",
    "  * `open('filename', 'wb').write(r.content)`\n",
    "3. Use the [Archives Unleashed Toolkit](https://aut.docs.archivesunleashed.org/docs/extract-binary) (if you have access to the W/ARC files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yoFE2xLAlwk"
   },
   "source": [
    "If you wanted to download the JSON files using the replay URL, below a is method for doing so.\n",
    "\n",
    "First, you'll want to setup a replay url base url. Here we'll use the Archive-It Wayback instance for the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxrOHn_2AicZ"
   },
   "outputs": [],
   "source": [
    "wayback_url = \"ARCHCOLLECTIONIDURL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCTmrEBGA-Yd"
   },
   "source": [
    "Next we'll create a new column using a lambda function. If you're familiar working with spreadsheets, what we're doing here is basically concatenating some column values together and creating a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5HoWxkFA6C8"
   },
   "outputs": [],
   "source": [
    "json[\"replay_url\"] = json.apply(\n",
    "    lambda row: str(wayback_url + str(row[\"crawl_date\"]) + \"/\" + row[\"url\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q87tSYyIBIiZ"
   },
   "source": [
    "Then we can export that new column we created out to a file, so we can use it with `wget` to download all the JSON files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyhpsf9wBN1a"
   },
   "outputs": [],
   "source": [
    "json[\"replay_url\"].head().to_csv(\"json_urls.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81a3q7feu5Ji"
   },
   "source": [
    "Finally, we can pass the file to `wget` to use as a download list. You can also speed this process up using `xargs` or `parallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_p4qGKoBRaZ",
    "outputId": "4aeb3d0f-70e2-4376-b442-8cfad0165406"
   },
   "outputs": [],
   "source": [
    "!wget --random-wait -i json_urls.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
